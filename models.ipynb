{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hello again\n",
    "\n",
    "## Let's do some ML\n",
    "\n",
    "We're assuming you have the data ready, the data should be in the form of **X**, **y**\n",
    "\n",
    "**X** are all the feature data , training and test\n",
    "\n",
    "**y** are all the labels, training and test\n",
    "\n",
    "**If you've already split your data, make sure you use a version without splitting** We'll be using KFold Cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some imports as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras._impl import keras\n",
    "import pandas as pd\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any imports you may need to load your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load our data  ( You should not need to do the below, and just load your X, y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('titanic_data.csv')\\\n",
    "    .dropna()\\\n",
    "    .drop(columns=['Ticket', 'PassengerId', 'Name', 'Cabin', 'Embarked'])\n",
    "data['Sex'] = data['Sex'].apply({'female':0, 'male': 1}.get)\n",
    "data['Fare'] = (data['Fare'] - data['Fare'].min()) / ( data['Fare'].max() - data['Fare'].min())\n",
    "data['Age'] = (data['Age'] - data['Age'].min()) / ( data['Age'].max() - data['Age'].min())\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "X = data.drop(columns=\"Survived\")# Drop 'Survived', which is a column (axis 1) from our original data frame\n",
    "y = data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your X, y here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get our hands dirty with Tensorflow\n",
    "\n",
    "We'll be using the high level API within Tensorflow as they provide the following benefits:\n",
    "\n",
    "- You can run Estimators-based models on a local host or on a distributed multi-server environment without changing your model. Furthermore, you can run Estimators-based models on CPUs, GPUs, or TPUs without recoding your model.\n",
    "- Estimators simplify sharing implementations between model developers.\n",
    "- You can develop a state of the art model with high-level intuitive code, In short, it is generally much easier to create models with Estimators than with the low-level TensorFlow APIs.\n",
    "- Estimators are themselves built on tf.layers, which simplifies customization.\n",
    "- Estimators build the graph for you. In other words, you don't have to build the graph.\n",
    "- Estimators provide a safe distributed training loop that controls how and when to:\n",
    "\t- build the graph\n",
    "\t- initialize variables\n",
    "\t- start queues\n",
    "\t- handle exceptions\n",
    "\t- create checkpoint files and recover from failures\n",
    "\t- save summaries for TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we need to do to use an estimator?\n",
    "\n",
    "- [ ] **One or more dataset import functions:** You can write the functions to return your X, y, \n",
    "- [ ] **Define a feature column:** Define the names and types of features\n",
    "- [ ] **An estimator:** We'll be looking at LinearRegressor, and LinearClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset import functions\n",
    "They are essentially functions that the estimator will call to get its data, this separation allows a very easy swap of data sources.\n",
    "\n",
    "You can also build a custom pipeline to do all the preprocessing that we've done so far. [more details](https://www.tensorflow.org/programmers_guide/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We use the helper function numpy_input_fn it allows a good level of customization\n",
    "batch_size = 10 # How many batches do we split our data\n",
    "num_epochs = 10 # How many times do we loop over the data\n",
    "shuffle = True\n",
    "## These parameters will create a function that feeds the estimator the following:\n",
    "## batches of 10 examples every iteration (model weights update)\n",
    "## 890 ( total examples ) / 10 == 89 iterations\n",
    "## 10 epochs * 89 iterations = 890 iterations \n",
    "\n",
    "## The function should return a features dictionary, and labels\n",
    "def get_input_fn(input_x, input_y, num_epochs=1, batch_size=1, shuffle=False):\n",
    "    # Transform our dataframe into a features dictionary\n",
    "    x_dict = input_x.to_dict(orient='list')\n",
    "    for input_x_item in x_dict:\n",
    "        x_dict[input_x_item] = np.array(x_dict[input_x_item])\n",
    "        \n",
    "    # Call the numpy_input_fn helper to create a function that returns dataset in batches    \n",
    "    return tf.estimator.inputs.numpy_input_fn(\n",
    "            x=x_dict,\n",
    "            y=input_y,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=num_epochs,\n",
    "            shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_input_fn():\n",
    "    # Define your function here, the function should return \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's data, now what\n",
    "\n",
    "- [x] **One or more dataset import functions:**\n",
    "- [ ] **Define a feature column:**\n",
    "- [ ] **An estimator:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining feature columns\n",
    "\n",
    "Each tf.feature_column identifies a feature name, its type, and any input pre-processing \n",
    "\n",
    "For example:\n",
    "- **numeric_column:** Represents real valued or numerical features.\n",
    "- **categorical_column_with_hash_bucket:** Represents sparse features where ids are set by hashing.\n",
    "\n",
    "We've already transformed all our data to numbers, so, it will all be numerical\n",
    "\n",
    "[more on feature_columns](https://www.tensorflow.org/api_docs/python/tf/feature_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "for col in X.columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(col))\n",
    "                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your feature_columns here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 down, 1 to go\n",
    "\n",
    "- [x] **One or more dataset import functions:**\n",
    "- [x] **Define a feature column:**\n",
    "- [ ] **An estimator:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On to the estimator,\n",
    "\n",
    "Estimators wrap the logic needed to run the experiment, the dataset, the features, and the model.\n",
    "\n",
    "[See more on estimators](https://www.tensorflow.org/api_docs/python/tf/estimator)\n",
    "\n",
    "\n",
    "Let's start with a simple pre-built estimators, since I'm predicting a class for my data, I'll use a [LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier),\n",
    "However, depending on your problem type, you may want to use a [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's define it as a function, so we can reuse it cleanly when needed \n",
    "## Modify this to return the appropriate estimator for your problem type\n",
    "\n",
    "## You can also specify model_dir or use the temporary one to view with tensorboard\n",
    "def get_estimator():\n",
    "    return tf.estimator.LinearClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great! now we have all the things we need to start training\n",
    "\n",
    "- [x] **One or more dataset import functions:**\n",
    "- [x] **Define a feature column:**\n",
    "- [x] **An estimator:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define our experiment function to tie things together\n",
    "\n",
    "def run_experiment(X_train, y_train, X_test, y_test):\n",
    "    print(\"X_train: {}, y_train:{}, X_test: {}, y_test: {}\".format(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "    estimator = get_estimator()\n",
    "    train_input_fn = get_input_fn(X_train, y_train, batch_size=10, num_epochs=10, shuffle=True)\n",
    "    estimator.train(input_fn=train_input_fn)\n",
    "    test_input_fn = get_input_fn(X_test, y_test, batch_size=len(X_test))\n",
    "    return estimator.evaluate(input_fn=test_input_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 91, y_train:91, X_test: 92, y_test: 92\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqrFXpg\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11879c490>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqrFXpg', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqrFXpg/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.931472, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 91 into /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqrFXpg/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.6296344.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-06-13:23:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqrFXpg/model.ckpt-91\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-06-13:23:29\n",
      "INFO:tensorflow:Saving dict for global step 91: accuracy = 0.70652175, accuracy_baseline = 0.67391306, auc = 0.75349456, auc_precision_recall = 0.82702464, average_loss = 0.5297583, global_step = 91, label/mean = 0.67391306, loss = 48.73776, precision = 0.7777778, prediction/mean = 0.66514367, recall = 0.7903226\n",
      "X_train: 92, y_train:92, X_test: 91, y_test: 91\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqNFYNc\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11879c9d0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqNFYNc', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqNFYNc/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.931472, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 92 into /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqNFYNc/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.948175.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-06-13:23:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2c/_zmrrhgj4k5dn9j66nmjcs1m0000zz/T/tmpqNFYNc/model.ckpt-92\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-06-13:23:33\n",
      "INFO:tensorflow:Saving dict for global step 92: accuracy = 0.6923077, accuracy_baseline = 0.6703297, auc = 0.7453551, auc_precision_recall = 0.8539324, average_loss = 0.5485406, global_step = 92, label/mean = 0.6703297, loss = 49.917194, precision = 0.8113208, prediction/mean = 0.59252745, recall = 0.704918\n",
      "Avg prevision: 0.794549286366 , (+/- 0.02 %)\n"
     ]
    }
   ],
   "source": [
    "# Now we just need to run our experiment one or more times ( If we're doing KFold for instance )\n",
    "kfold = StratifiedKFold(n_splits=2, shuffle=True, random_state=10)\n",
    "cv_precisions = []\n",
    "with tf.Session() as sess:\n",
    "    for train_index, test_index in kfold.split(np.array(X), np.array(y)):\n",
    "        score = run_experiment(X.iloc[train_index], y.iloc[train_index].values, X.iloc[test_index], y.iloc[test_index].values)\n",
    "        cv_precisions.append(score['precision'])\n",
    "        \n",
    "print(\"------------------------------------\")\n",
    "print(\"Avg precision: {} , (+/- {:.2f} %)\".format(np.mean(cv_precisions), np.std(cv_precisions)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
